{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dockerizing R code modules and converting to FireCloud Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Basic Docker documentation can be found at https://docs.docker.com/. \n",
    "* Use the `r-base` image as the starting image for all R programs. `r-base` documentation can be found at https://hub.docker.com/_/r-base/. \n",
    "    + `r-base` can be used in interactive mode (try running in a terminal):\n",
    "    <p>`$ docker run -ti --rm r-base`<p>\n",
    "    + in batch/script mode (`-v` option to link local directory to docker image):\n",
    "    <p>`$ docker run -ti --rm -v \"$PWD\":/home/docker -w /home/docker -u docker r-base R CMD check .`<p>\n",
    "    + or invoke a shell in the container to then run `R` or `Rscript`:\n",
    "    <p>`$ docker run -ti --rm r-base /usr/bin/bash`<p>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Create a docker image with R-utilites\n",
    "* Create directory r-util and add a `Dockerfile` to the directory for specifying the new image with the associated R code. In this directory, include all code/files that need to be incorporated into the image. R libraries can be automatically installed using the code shown below (also see https://blog.jessfraz.com/post/r-containers-for-data-science/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# on the Mac with flynn://prot_proteomics mouted\n",
    "cd /Volumes/prot_proteomics/Projects/PGDAC/docker\n",
    "mkdir r-util\n",
    "cd r-util\n",
    "cp -r /Volumes/prot_proteomics/LabMembers/manidr/R-utilities .\n",
    "cat > Dockerfile <<EOF\n",
    "\n",
    "FROM r-base\n",
    "MAINTAINER manidr@broadinstitute.org\n",
    "\n",
    "# external dependencies for installing pacman library in R\n",
    "# with pacman, any missing libraries will be automatically added\n",
    "RUN apt-get update\n",
    "RUN apt-get -t unstable install -y libssl-dev\n",
    "RUN apt-get -t unstable install -y libcurl4-openssl-dev\n",
    "\n",
    "# install packages\n",
    "RUN echo 'install.packages(c( \\\n",
    "    \"MASS\", \\\n",
    "    \"MethComp\", \\\n",
    "    \"NMF\", \\\n",
    "    \"PerformanceAnalytics\", \\\n",
    "    \"RColorBrewer\", \\\n",
    "    \"RankAggreg\", \\\n",
    "    \"RobustRankAggreg\", \\\n",
    "    \"bpca\", \\\n",
    "    \"caret\", \\\n",
    "    \"e1071\", \\\n",
    "    \"fastcluster\", \\\n",
    "    \"ggplot2\", \\\n",
    "    \"glmnet\", \\\n",
    "    \"gplots\", \\\n",
    "    \"lattice\", \\\n",
    "    \"limma\", \\\n",
    "    \"lme4\", \\\n",
    "    \"maptools\", \\\n",
    "    \"mclust\", \\\n",
    "    \"misc3d\", \\\n",
    "    \"mixtools\", \\\n",
    "    \"nlme\", \\\n",
    "    \"pacman\", \\\n",
    "    \"pamr\", \\\n",
    "    \"parmigene\", \\\n",
    "    \"psych\", \\\n",
    "    \"randomForest\", \\\n",
    "    \"reshape\", \\\n",
    "    \"rgl\", \\\n",
    "    \"rhdf5\", \\\n",
    "    \"samr\", \\\n",
    "    \"scales\", \\\n",
    "    \"scatterplot3d\", \\\n",
    "    \"smacof\", \\\n",
    "    \"sn\", \\\n",
    "    \"tensor\", \\\n",
    "    \"tools\", \\\n",
    "    \"verification\" \\\n",
    "), repos=\"http://cran.us.r-project.org\", dependencies=TRUE)' > /tmp/packages.R  \\\\\n",
    "   && Rscript /tmp/packages.R\n",
    "# bioconductor libraries\n",
    "RUN echo 'source(\"https://bioconductor.org/biocLite.R\"); biocLite(\"Biobase\"); biocLite(\"graph\"); biocLite(\"Rgraphviz\"); biocLite(\"impute\"); biocLite(\"rhdf5\")' > /tmp/biocpkgs.R \\\\\n",
    "   && Rscript /tmp/biocpkgs.R\n",
    "\n",
    "COPY R-utilities/ /prot/proteomics/Projects/R-utilities\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After creating the Dockerfile, call `build` and then `run` the container:\n",
    "<p>`$ docker build --rm -t broadcptac/r-util:1 .`<p>\n",
    "<p>`$ docker run -ti --rm -v $(pwd)/data:/home/user/data r-util R CMD <script>`<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a docker image with PGDAC basic pipeline\n",
    "* Create directory pgdac-basic, add a `Dockerfile` to the directory, copy associated R code and build the docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# on the Mac with flynn://prot_proteomics mouted\n",
    "cd /Volumes/prot_proteomics/Projects/PGDAC/docker\n",
    "mkdir pgdac-basic\n",
    "cd pgdac-basic\n",
    "cp -r ../../src .\n",
    "cat > Dockerfile <<EOF\n",
    "\n",
    "FROM broadcptac/r-util:1\n",
    "MAINTAINER manidr@broadinstitute.org\n",
    "\n",
    "COPY src /prot/proteomics/Projects/PGDAC/src\n",
    "\n",
    "EOF\n",
    "\n",
    "docker build --rm -t broadcptac/pgdac-basic:1 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setup FireCloud/WDL/Cromwell environment and test workflow\n",
    "See the README.md and Wiki at https://github.com/broadinstitute/gdac-firecloud for documentation. The gdac-firecloud repository has a make system that automates workflow create and testing. See https://github.com/broadinstitute/gdac-firecloud/wiki/Using-Make and https://github.com/broadinstitute/gdac-firecloud/wiki/Adding-Tasks-and-Workflows-to-Firecloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# use gdac-firecloud to create and test a workflow\n",
    "cd /Volumes/prot_proteomics/Projects/PGDAC/\n",
    "use .git-2.11.0-with-svn\n",
    "git clone git://github.com/broadinstitute/gdac-firecloud.git\n",
    "\n",
    "# create a workflow for the PGDAC pipeline\n",
    "cd gdac-firecloud/workflows\n",
    "make template FLOW=pgdac_basic\n",
    "cp ../../wdl/workflows/pgdac_basic/pgdac_basic.wdl pgdac_basic/.   # copy previously created workflow description\n",
    "cd pgdac_basic\n",
    "make validate\n",
    "make inputs   # edit tests/inputs.json to set parameters for workflow\n",
    "make run  # if errors, try: java -Xmx4096m -jar ../../bin/cromwell.jar run pgdac_basic.wdl tests/inputs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Upload docker image to docker hub\n",
    "FireCloud retrieves docker images from the docker hub. In order to use the image in a FireCloud workflow, upload (push) docker image:\n",
    "* Create a docker hub account (username: manidr)\n",
    "* Click on \"Organizations\" and create a new broadcptac organization on docker hub under manidr's account\n",
    "* Under the broadcptac organization, create a pgdac_basic repository\n",
    "* Also upload r-utils docker image (so that it can be retrieved later, if lost on the local computer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "docker login -u manidr\n",
    "docker push broadcptac/r-util:1\n",
    "docker push broadcptac/pgdac_basic:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Upload workflow code to FireCloud\n",
    "One approach is to run the broadinstitute/firecloud-cli docker image and upload the wdl workflow. An alternative is to set the Makefile.my in gdac-firecloud and then run \"make push_wdl\". Also see workshop materials in the PGDAC/firecloud directory for additional documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /Volumes/prot_proteomics/Projects/PGDAC/gdac-firecloud/workflows/pgdac_basic\n",
    "\n",
    "docker run --rm -it -v \"$HOME\"/.config:/.config -v \"$PWD\":/working broadinstitute/firecloud-cli bash\n",
    "# in the running docker, authenticate google cloud\n",
    "gcloud auth login\n",
    "# then upload wdl to firecloud using CLI, to the broadcptac workspace\n",
    "# if the workspace specified by -s does not exist, it will be created\n",
    "firecloud -u https://api.firecloud.org/api -m push -s broadcptac -n pgdac_basic -t Workflow -y \"PGDAC basic pipeline\" pgdac_basic.wdl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create FireCloud workflow and run it\n",
    "Use the directions in https://github.com/broadinstitute/gdac-firecloud/wiki/Adding-Tasks-and-Workflows-to-Firecloud#5-create-and-execute-a-workspace-method-configuration and additional FireCloud documentation to create a new workflow in FireCloud, set parameters, upload data and run the analysis:\n",
    "* Create a new workspace in FireCloud (Test workflow is nci-manidr-broadinstitute-org/broad-cptac-pgdac-pipeline-test)\n",
    "* Import the pgdac_basic method into the workspace\n",
    "* Upload input data files to the bucket associated with the workspace (using the GUI or gsutil). Ensure that the correct user is selected -- else bucket will not show contents, with a permission denied error.\n",
    "* Use the data tab to import the PGDAC/firecloud/pgdac_basic/participant.tsv file\n",
    "* In the Method Configurations tab, select pgdac_basic and edit each of the input parameter fields to point to appropriate columns in the participant.tsv file (this.<colname>)\n",
    "* Finally click Launch Analysis in the Method Configurations tab to run the pipeline."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
